{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99a70ca5-b4ab-4e66-b8c7-ec78214ff65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following script splits a file into \"num_files\" number of smaller files.\n",
    "#Very useful for analyzing large files that are difficult to manipulate and/or process.\n",
    "#Example is for json format but can be used for any text file.\n",
    "#Note that the resulting json files will need to be manually updated to include the closing ].\n",
    "\n",
    "import json\n",
    "\n",
    "def split_json_file(input_file, num_files):\n",
    "    # Determine the size of each chunk\n",
    "    with open (input_file) as f:\n",
    "        size = sum(1 for line in f)\n",
    "    chunk_size = size // num_files\n",
    "    remainder = size % num_files\n",
    "    \n",
    "    # Split the data into chunks and save each chunk to a separate file\n",
    "    with open(input_file) as f:\n",
    "        for i in range (num_files) :\n",
    "            chunk_length = chunk_size + (1 if i < remainder else 0)\n",
    "            output_file = f\"{input_file}.{i+1}.json\"\n",
    "            with open(output_file, \"w\") as out_f: \n",
    "                for j in range(chunk_length):\n",
    "                    line = f.readline()\n",
    "                    if not line:\n",
    "                        break \n",
    "                    out_f.write(line)\n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"large-file.json\"\n",
    "    num_files = 5 #edit as needed\n",
    "    split_json_file(input_file, num_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bdad337-5983-4e1e-9f3d-ef18bf4eb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following script will search fileB for all words in fileA.\n",
    "#It will write all found words into fileC.\n",
    "#Useful for reconciliation/analysis purposes in large files.\n",
    "\n",
    "#Open and read the content of fileA\n",
    "with open('fileA.txt', 'r') as fileA:\n",
    "        words = fileA.read().split()\n",
    "\n",
    "#Open and read the content of fileB\n",
    "with open('fileB.txt', 'r') as fileB:\n",
    "        content = fileB.read()\n",
    "\n",
    "found_items = []\n",
    "\n",
    "#Search for each item in fileB and print it if found\n",
    "for word in words:\n",
    "    if word in content:\n",
    "        found_items.append(word)\n",
    "        \n",
    "        with open('found_items.txt', 'w') as found_items_file:\n",
    "            for word in found_items:\n",
    "                found_items_file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e950aa-37e2-4a7a-8e40-74e9d67e47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following script is used to flatten json files, which can be exported to csv/excel format for easier analysis.\n",
    "#The current version takes as parameter only one key from one node. It needs to be extended to retrieve all key pair values in all nodes.\n",
    "\n",
    "import pandas as pd\n",
    "def flatten_json(nested_json, exclude = ['']):\n",
    "    \n",
    "    out = {}\n",
    "    \n",
    "    def flatten(x, name = '', exclude = exclude):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                if a not in exclude: \n",
    "                    flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i+=1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "            \n",
    "    flatten(nested_json)\n",
    "    return out\n",
    "\n",
    "df = pd.read_json(\"small_file.json\")\n",
    "result = pd.DataFrame([flatten_json(x) for x in df['actor']])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a399e-1e0f-41eb-b780-a8f67f7db300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following script removes all numerical characters from file names in order to make them more generic.\n",
    "#The resulting file names need to be unique.\n",
    "#This step can be used as a prerequisite in regression analysis for files with names that contain variable content, such as dates.\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "for root, dirs, files in os.walk('./test_folder'):\n",
    "    for file_name in files:\n",
    "        #Create full path to file\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        try:\n",
    "            #Extract the file extension\n",
    "            file_base, file_ext = os.path.splitext(file_name)\n",
    "            \n",
    "            #Remove numbers from the file base\n",
    "            new_file_base = re.sub(r'\\d', '', file_base)\n",
    "            \n",
    "            #Construct the new file name\n",
    "            new_file_name = new_file_base + file_ext\n",
    "            \n",
    "            #Create the full path to the new file\n",
    "            new_file_path = os.path.join(root, new_file_name)\n",
    "            \n",
    "            #Rename the file if the new name is different\n",
    "            if file_path != new_file_path:\n",
    "                os.rename(file_path, new_file_path)\n",
    "                print(f'Renamed: {file_name} to {new_file_name}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file_name}: {str(e)}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761ef48-fcc6-49d4-88ae-10377e438c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder structure: useful for saving output corresponding to a certain user or date.\n",
    "#This script needs to be saved in a .py file and executed on a Linux machine at the desired location.\n",
    "#Does not work in Jupyter Lab.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "DATE = \"Test_date\"\n",
    "ENV = \"Test_env\"\n",
    "Subfolder1 = \"Test1\"\n",
    "Subfolder2 = \"Test2\"\n",
    "Subfolder3 = \"Test3\"\n",
    "#Add more as needed\n",
    "\n",
    "folder_structure = [DATE, ENV, Subfolder1]\n",
    "\n",
    "full_path = \"\"\n",
    "for folder in folder_structure:\n",
    "    full_path = os.path.join(full_path, folder)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.mkdir(full_path)\n",
    "\n",
    "folder_structure = [DATE, ENV, Subfolder2]\n",
    "\n",
    "full_path = \"\"\n",
    "for folder in folder_structure:\n",
    "    full_path = os.path.join(full_path, folder)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.mkdir(full_path)\n",
    "        \n",
    "folder_structure = [DATE, ENV, Subfolder2]\n",
    "\n",
    "full_path = \"\"\n",
    "for folder in folder_structure:\n",
    "    full_path = os.path.join(full_path, folder)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.mkdir(full_path)\n",
    "\n",
    "#add steps for all required subfolders\n",
    "\n",
    "print(\"Folder structure created successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
